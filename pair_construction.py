"""
Pair Construction module.

This module builds training pairs from model responses classified by correctness and confidence.
It extracts positive-negative pairs from responses generated by different models.

python src/data/pair_construction.py \
  --dataset_type numina_math \
  --model1_file data/results/llama3_1_8b.json \
  --model2_file data/results/qwen_72b.json \
  --model3_file data/results/mistral87.json \
  --model1_name llama \
  --model2_name qwen \
  --model3_name mistral \
  --output_dir data/processed/pairs \
  --responses_per_question 5 \
  --seed 42
"""

import os
import json
import random
import logging
from typing import Dict, List, Tuple, Any, Set, Optional
from tqdm import tqdm

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class PairConstructor:
    """
    Constructs training pairs from model responses for reward model training.
    
    Extracts pairs with class_1 (Correct & Certain) as positive examples
    and other classes as negative examples.
    """
    
    def __init__(self, responses_per_question: int = 5, seed: int = 42):
        """
        Initialize the pair constructor.
        
        Args:
            responses_per_question: Number of responses generated per question
            seed: Random seed for reproducibility
        """
        self.responses_per_question = responses_per_question
        self.seed = seed
        random.seed(seed)
    
    def load_data(self, file_path: str) -> List[Dict]:
        """
        Load data from a JSON file.
        
        Args:
            file_path: Path to the JSON file
            
        Returns:
            List of data items
        """
        try:
            logger.info(f"Loading data from {file_path}")
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            logger.info(f"Loaded {len(data)} items")
            return data
        except Exception as e:
            logger.error(f"Error loading file {file_path}: {e}")
            return []
    
    def save_data(self, data: List[Dict], file_path: str) -> None:
        """
        Save data to a JSON file.
        
        Args:
            data: Data to save
            file_path: Output file path
        """
        try:
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logger.info(f"Saved {len(data)} items to {file_path}")
        except Exception as e:
            logger.error(f"Error saving to {file_path}: {e}")
    
    def format_question(self, item: Dict, dataset_type: str) -> str:
        """
        Format a question based on dataset type.
        
        Args:
            item: Dataset item
            dataset_type: Type of dataset
            
        Returns:
            Formatted question string
        """
        if dataset_type == "numina_math":
            question = item.get("problem", "No question provided")
            return f"Question:\n{question}"
        
        elif dataset_type == "sciknoweval":
            question = item.get("question", "No question provided")
            choices_text = " ".join(
                [f"{label}. {text}" for label, text in zip(item["choices"]["label"], item["choices"]["text"])]
            )
            return f"Question:\n{question}\nOptions:\n{choices_text}"
        
        elif dataset_type == "scieval":
            question = item.get("question", "No question provided")
            return f"Question:\n{question}"
        
        elif dataset_type == "logicnli":
            premise = item.get("premise", "No question provided")
            hypothesis = item.get("hypothesis", "No question provided")
            return f"Question:\n{premise}\n\nHypothesis:\n{hypothesis}"
        
        elif dataset_type == "logiqa":
            text = item.get("text", "No background information provided")
            question = item.get("question", "No question provided")
            options = item.get("options", [])
            options_text = " ".join([f"{chr(65 + i)}. {option}" for i, option in enumerate(options)])
            return f"Background:\n{text}\n\nQuestion:\n{question}\nOptions:\n{options_text}"
        
        else:
            # Default format for other dataset types
            if "question" in item:
                return f"Question:\n{item['question']}"
            return f"Question:\n{item.get('problem', 'No question provided')}"
    
    def extract_pairs_from_classes(
        self, 
        class_1_items: List[Dict], 
        other_class_items: List[Dict],
        dataset_type: str,
        max_pairs: int = 1
    ) -> Tuple[List[Dict], List[str]]:
        """
        Extract pairs from class_1 items and items from another class.
        
        Args:
            class_1_items: List of class_1 items (positive examples)
            other_class_items: List of items from another class (negative examples)
            dataset_type: Type of dataset
            max_pairs: Maximum number of pairs to extract
            
        Returns:
            Tuple of (pairs, pair_sources)
        """
        used_model_outputs = set()
        pairs = []
        pair_sources = []  # Track source models for each pair
        
        # Create copies to avoid modifying the original lists
        class_1_copy = class_1_items.copy()
        other_class_copy = other_class_items.copy()
        
        while class_1_copy and other_class_copy and len(pairs) < max_pairs:
            # Select a random class_1 item (positive example)
            class_1_item = random.choice(class_1_copy)
            
            # Skip if this output has already been used
            if class_1_item["model_output"] in used_model_outputs:
                class_1_copy.remove(class_1_item)
                continue
            
            class_1_copy.remove(class_1_item)
            used_model_outputs.add(class_1_item["model_output"])
            
            # Select a random item from the other class (negative example)
            other_item = random.choice(other_class_copy)
            other_class_copy.remove(other_item)
            
            # Track source models
            chosen_source = class_1_item.get("source_model", "unknown")
            rejected_source = other_item.get("source_model", "unknown")
            
            # Create the pair
            pair = {
                "instruction": self.format_question(class_1_item, dataset_type),
                "input": "",
                "chosen": class_1_item["model_output"],
                "rejected": other_item["model_output"]
            }
            
            pairs.append(pair)
            pair_sources.append(f"{chosen_source}-{rejected_source}")
        
        return pairs, pair_sources
    
    def construct_pairs(
        self, 
        model_data_files: Dict[str, str],
        output_files: Dict[str, str],
        dataset_type: str
    ) -> Dict[str, Any]:
        """
        Construct pairs from multiple model data files.
        
        Args:
            model_data_files: Dictionary mapping model names to data files
            output_files: Dictionary mapping pair types to output files
            dataset_type: Type of dataset
            
        Returns:
            Statistics about the constructed pairs
        """
        # Load data from each model file
        model_data = {}
        for model_name, file_path in model_data_files.items():
            data = self.load_data(file_path)
            
            # Add source model information to each item
            for item in data:
                item["source_model"] = model_name
            
            model_data[model_name] = data
        
        # Find the minimum length across all datasets
        min_length = min(len(data) for data in model_data.values())
        logger.info(f"Using {min_length} items from each model")
        
        # Initialize containers for pairs and statistics
        pairs = {
            "class_1_2": [],
            "class_1_3": [],
            "class_1_4": []
        }
        
        sources = {
            "class_1_2": [],
            "class_1_3": [],
            "class_1_4": []
        }
        
        # Process data in groups based on responses_per_question
        for i in tqdm(range(0, min_length, self.responses_per_question), desc="Constructing pairs"):
            # Get corresponding question groups from each model
            model_groups = {}
            question_match = True
            
            # Extract the same question from each model
            for model_name, data in model_data.items():
                group = data[i:i+self.responses_per_question]
                model_groups[model_name] = group
                
                # Verify that all models have the same question
                if model_name != list(model_data.keys())[0]:
                    first_model = list(model_data.keys())[0]
                    if group[0].get("question", "") != model_data[first_model][i].get("question", ""):
                        question_match = False
                        break
            
            # Skip if questions don't match across models
            if not question_match:
                logger.warning(f"Question mismatch at index {i}, skipping")
                continue
            
            # Combine all responses for this question
            all_items = []
            for group in model_groups.values():
                all_items.extend(group)
            
            # Categorize by class label
            class_items = {
                "class_1": [],
                "class_2": [],
                "class_3": [],
                "class_4": []
            }
            
            for item in all_items:
                label = item.get("class_label")
                if label in class_items:
                    class_items[label].append(item)
            
            # Extract pairs for each class combination
            if class_items["class_1"] and class_items["class_2"]:
                new_pairs, new_sources = self.extract_pairs_from_classes(
                    class_items["class_1"], 
                    class_items["class_2"],
                    dataset_type,
                    max_pairs=1
                )
                pairs["class_1_2"].extend(new_pairs)
                sources["class_1_2"].extend(new_sources)
            
            if class_items["class_1"] and class_items["class_3"]:
                new_pairs, new_sources = self.extract_pairs_from_classes(
                    class_items["class_1"], 
                    class_items["class_3"],
                    dataset_type,
                    max_pairs=1
                )
                pairs["class_1_3"].extend(new_pairs)
                sources["class_1_3"].extend(new_sources)
            
            if class_items["class_1"] and class_items["class_4"]:
                new_pairs, new_sources = self.extract_pairs_from_classes(
                    class_items["class_1"], 
                    class_items["class_4"],
                    dataset_type,
                    max_pairs=1
                )
                pairs["class_1_4"].extend(new_pairs)
                sources["class_1_4"].extend(new_sources)
        
        # Save pairs to output files
        for pair_type, file_path in output_files.items():
            if pair_type in pairs:
                self.save_data(pairs[pair_type], file_path)
        
        # Calculate statistics
        stats = self.calculate_statistics(sources, pairs)
        return stats
    
    def calculate_statistics(self, sources: Dict[str, List[str]], pairs: Dict[str, List[Dict]]) -> Dict[str, Any]:
        """
        Calculate statistics about the constructed pairs.
        
        Args:
            sources: Dictionary of source model pairs for each class combination
            pairs: Dictionary of constructed pairs for each class combination
            
        Returns:
            Statistics dictionary
        """
        stats = {}
        
        # Count model combinations for each class pair type
        for pair_type, source_list in sources.items():
            combo_counts = self.count_model_combinations(source_list)
            
            stats[pair_type] = {
                "total": len(pairs[pair_type]),
                "combinations": combo_counts
            }
        
        # Add total pair count
        total_pairs = sum(len(p) for p in pairs.values())
        stats["total_pairs"] = total_pairs
        
        return stats
    
    def count_model_combinations(self, source_list: List[str]) -> Dict[str, int]:
        """
        Count the occurrences of model combinations in source list.
        
        Args:
            source_list: List of model source combinations (e.g., ["llama-qwen", "mistral-llama"])
            
        Returns:
            Dictionary with counts for each combination type
        """
        # Initialize counters for all potential combinations
        combinations = {}
        
        for source in source_list:
            if source in combinations:
                combinations[source] += 1
            else:
                combinations[source] = 1
        
        # Group related combinations (e.g., llama-qwen and qwen-llama)
        simplified = {}
        for combo, count in combinations.items():
            models = combo.split('-')
            if len(models) == 2:
                # Create bidirectional key (e.g., llama-qwen for both llama-qwen and qwen-llama)
                sorted_models = tuple(sorted(models))
                key = f"{sorted_models[0]}-{sorted_models[1]}"
                
                if key in simplified:
                    simplified[key] += count
                else:
                    simplified[key] = count
            else:
                # Handle unexpected format
                if "other" in simplified:
                    simplified["other"] += count
                else:
                    simplified["other"] = count
        
        return simplified


def main():
    """Main entry point with command line argument handling."""
    import argparse
    
    parser = argparse.ArgumentParser(description="Construct training pairs from classified model responses")
    parser.add_argument("--dataset_type", required=True, 
                        choices=["numina_math", "sciknoweval", "scieval", "logicnli", "logiqa", "other"],
                        help="Type of dataset being processed")
    parser.add_argument("--model1_file", required=True, help="Path to first model's data file")
    parser.add_argument("--model2_file", required=True, help="Path to second model's data file")
    parser.add_argument("--model3_file", required=True, help="Path to third model's data file")
    parser.add_argument("--model1_name", default="model1", help="Name for first model")
    parser.add_argument("--model2_name", default="model2", help="Name for second model")
    parser.add_argument("--model3_name", default="model3", help="Name for third model")
    parser.add_argument("--output_dir", required=True, help="Output directory for pair files")
    parser.add_argument("--responses_per_question", type=int, default=5, 
                        help="Number of responses generated per question")
    parser.add_argument("--seed", type=int, default=42, help="Random seed")
    
    args = parser.parse_args()
    
    # Create output directory if it doesn't exist
    os.makedirs(args.output_dir, exist_ok=True)
    
    # Construct output file paths
    output_files = {
        "class_1_2": os.path.join(args.output_dir, "pair_12.json"),
        "class_1_3": os.path.join(args.output_dir, "pair_13.json"),
        "class_1_4": os.path.join(args.output_dir, "pair_14.json")
    }
    
    # Set up model data files
    model_data_files = {
        args.model1_name: args.model1_file,
        args.model2_name: args.model2_file,
        args.model3_name: args.model3_file
    }
    
    # Create pair constructor and build pairs
    constructor = PairConstructor(
        responses_per_question=args.responses_per_question,
        seed=args.seed
    )
    
    stats = constructor.construct_pairs(
        model_data_files=model_data_files,
        output_files=output_files,
        dataset_type=args.dataset_type
    )
    
    # Save statistics
    stats_file = os.path.join(args.output_dir, "pair_statistics.json")
    constructor.save_data(stats, stats_file)
    
    # Print summary
    logger.info("\nPair construction summary:")
    logger.info(f"Class 1-2 pairs: {stats['class_1_2']['total']}")
    logger.info(f"Class 1-3 pairs: {stats['class_1_3']['total']}")
    logger.info(f"Class 1-4 pairs: {stats['class_1_4']['total']}")
    logger.info(f"Total pairs: {stats['total_pairs']}")
    logger.info(f"Statistics saved to: {stats_file}")


if __name__ == "__main__":
    main()